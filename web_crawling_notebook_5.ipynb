{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac8508e5",
   "metadata": {},
   "source": [
    "# Web Crawling with Python — Notebook 5\n",
    "## Ethical and Legal Considerations\n",
    "\n",
    "---\n",
    "\n",
    "### Why Ethics Matter in Crawling\n",
    "\n",
    "Web scraping can be powerful, but it comes with responsibilities.  \n",
    "You must always consider both **legal requirements** and **ethical behavior**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7e6b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Understanding robots.txt\n",
    "\n",
    "Most websites have a `/robots.txt` file that tells crawlers which pages are allowed or disallowed.\n",
    "\n",
    "**Questions:**\n",
    "- What should you do if `/robots.txt` tells you not to crawl certain pages?\n",
    "- Is it always legally binding?\n",
    "\n",
    "_Write your answers below:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1ba35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "667332d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Website Terms of Service\n",
    "\n",
    "Before crawling a site, you should always read its **Terms of Service (ToS)**.\n",
    "\n",
    "**Questions:**\n",
    "- What could happen if you violate a site’s ToS while crawling?\n",
    "- Where can you usually find the ToS on a website?\n",
    "\n",
    "_Write your answers below:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916066c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85a9b28b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 3: Respecting Website Resources\n",
    "\n",
    "Crawlers can put extra load on a website’s servers.\n",
    "\n",
    "**Starter:**  \n",
    "List three ways to reduce the impact of your crawler on a website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303976f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45ba155",
   "metadata": {},
   "source": [
    "# TODO: List at least three ways to reduce crawler impact\n",
    "#\n",
    "Example:\n",
    "- Slow down your crawl rate\n",
    "- Only crawl what you need\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eee5f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e99d183",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 4: Personal and Sensitive Data\n",
    "\n",
    "It is often illegal or unethical to scrape personal, sensitive, or copyrighted data.\n",
    "\n",
    "**Questions:**\n",
    "- What are some examples of personal or sensitive data you should not collect?\n",
    "- What could happen if you ignore data privacy laws (like GDPR)?\n",
    "\n",
    "_Write your answers below:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05f5e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb54129",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge: Real-World Scenarios\n",
    "\n",
    "Read the scenarios below and discuss if the crawling described is **ethical** and **legal**.  \n",
    "Give reasons for your answer.\n",
    "\n",
    "**Scenario 1:**  \n",
    "A student crawls a public news site to gather article headlines for a school project.\n",
    "\n",
    "**Scenario 2:**  \n",
    "A company scrapes users’ email addresses from a social media site for marketing.\n",
    "\n",
    "**Scenario 3:**  \n",
    "A researcher crawls millions of product pages from an online store every few seconds, ignoring `robots.txt`.\n",
    "\n",
    "_Write your analysis below:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d00d62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a3c403",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection\n",
    "\n",
    "- Why do you think ethical crawling is important for the web?\n",
    "- How will you make sure your projects follow best practices?\n",
    "\n",
    "_Write your final thoughts here:_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7bd15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
